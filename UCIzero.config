# Number of worker threads default 2
threadsCPU=8

# weight file default: <autodiscover>
weights=<autodiscover>

# Minibatch size for NN inference defaul: 256, min: 1, max: 1024  512 for 2080ti
minibatch-size=176

# Max prefetch nodes, per NN call defaul: 32, min: 0, max: 1024
max-prefetch=160

# Cpuct MCTS option defaul: 3.4f min: 0.0f, max: 100.0f, 2.5f
cpuct=1.9f

fpu-value=0.443f
cpuct-factor=2.815f
cpuct-base=18368
policy-softmax-temp=1.607
smart-pruning-minimum-batches=320
max-out-of-order-evals-factor=2.4
max-collision-events=917

# Display verbose move stats default: false
verbose-move-stats=false
# multipv=6

# Length of history to include in cache default: 1 max: 7
cache-history-length=0

# Allowed node collisions, per batch  defaul: 1 max: 1024
# max-collision-events=2048

# NNCache size defaul: 3200000, max: 999999999
nncache=40000000

# NN backend to use defaul: cudnn  multiplexing  backend=cudnn-fp16 backend=cudnn
backend=demux

# NN backend parameters default: (backend=cudnn,gpu=0) (backend=cudnn,gpu=0),(backend=cudnn,gpu=1),(backend=cudnn,gpu=2),(backend=cudnn,gpu=3)
#backend-opts=(backend=cudnn-auto,gpu=0),(backend=cudnn-auto,gpu=1),(backend=cudnn-auto,gpu=2),(backend=cudnn-auto,gpu=3),(backend=cudnn-auto,gpu=4),(backend=cudnn-auto,gpu=5),(backend=cudnn-auto,gpu=6),(backend=cudnn-auto,gpu=7)

backend-opts=(backend=cudnn-auto,gpu=0),(backend=cudnn-auto,gpu=1),(backend=cudnn-auto,gpu=2),(backend=cudnn-auto,gpu=3)

# engine can use openbook default: false
usebook=false


# Move time overhead in milliseconds defaul: 200
move-overhead=200

# endgame-paths 
# endgame-paths=none

# Ponder think defaul: true
ponder=true

moves-left-max-effect=0.2
moves-left-threshold=0.0
moves-left-slope=0.007
moves-left-quadratic-factor=0.85
moves-left-scaled-factor=0.15
moves-left-constant-factor=0.0
